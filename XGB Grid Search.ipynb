{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_xgboost = df_train\n",
    "df_test_xgboost = df_test\n",
    "\n",
    "def asignarMetros(metroscubiertos, metrostotales):\n",
    "    if (metroscubiertos != 0 and metrostotales == 0):\n",
    "        return metroscubiertos\n",
    "    else:\n",
    "        return metrostotales\n",
    "    \n",
    "def asignarMetrosLibres(metroscubiertos, metrostotales):\n",
    "    if (metroscubiertos != metrostotales):\n",
    "        return metrostotales-metroscubiertos\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#df_train_xgboost['metrostotales'].fillna(0, inplace=True)\n",
    "#df_train_xgboost['metrostotales'] = df_train_xgboost.apply(lambda x: asignarMetros(x['metroscubiertos'],x['metrostotales']),axis=1)\n",
    "#df_train_xgboost['metroslibres'] = df_train_xgboost.apply(lambda x: asignarMetrosLibres(x['metroscubiertos'],x['metrostotales']),axis=1)\n",
    "\n",
    "#df_test_xgboost['metrostotales'].fillna(0, inplace=True)\n",
    "#df_test_xgboost['metrostotales'] = df_test_xgboost.apply(lambda x: asignarMetros(x['metroscubiertos'],x['metrostotales']),axis=1)\n",
    "#df_test_xgboost['metroslibres'] = df_test_xgboost.apply(lambda x: asignarMetrosLibres(x['metroscubiertos'],x['metrostotales']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 15)\n",
      "(240000, 67)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   8 out of   8 | elapsed: 15.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   8 out of   8 | elapsed: 15.8min finished\n",
      "c:\\users\\manuel\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "c:\\users\\manuel\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246402143520269\n",
      "{'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "#----------------PREPROCESAMIENTO----------------\n",
    "\n",
    "df_train_xgboost = df_train_xgboost.drop(['ciudad','fecha','titulo','descripcion','direccion','idzona','lat','lng'], axis=1)\n",
    "df_test_xgboost = df_test_xgboost.drop(['ciudad','fecha','titulo','descripcion','direccion','idzona','lat','lng'], axis=1)\n",
    "#df_train_xgboost = df_train_xgboost.fillna(value = {'provincia': 0, 'tipodepropiedad': 0})\n",
    "\n",
    "print(df_train_xgboost.shape)\n",
    "#XGBoost maneja los NaNs, ver despues si lo dejamos como esta\n",
    "\n",
    "df_train_xgboost = pd.get_dummies(df_train_xgboost, drop_first=True)#, sparse = True)\n",
    "df_test_xgboost = pd.get_dummies(df_test_xgboost, drop_first=True)#, sparse = True)\n",
    "\n",
    "print(df_train_xgboost.shape)\n",
    "precio = df_train_xgboost['precio']\n",
    "df_train_xgboost.drop(labels=['precio'], axis=1,inplace = True)\n",
    "df_train_xgboost.insert(len(df_train_xgboost.columns), 'Precio', precio)\n",
    "\n",
    "X_train, y_train = df_train_xgboost.iloc[:,:-1],df_train_xgboost.iloc[:,-1]\n",
    "\n",
    "df_test_xgboost['tipodepropiedad_Garage'] = 0\n",
    "df_test_xgboost['tipodepropiedad_Hospedaje'] = 0\n",
    "df_test_xgboost = df_test_xgboost[list(X_train.columns.values)]\n",
    "\n",
    "xgb1 = XGBRegressor()\n",
    "\n",
    "#Ir cambiando parametros para ver como functiona\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [0.04], #probamos con 0.03,0.04,0.05,0.06,0.07\n",
    "              'max_depth': [9], #probamos con 5,6,7,8,9,10,11\n",
    "              'min_child_weight': [1], #Probamos con 1,2,3,4,5,6\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7], #probamos 0.3,0.4,0.5,0.6,0.7,0.8\n",
    "              'n_estimators': [700],  #Se probo con 400,500,600,700,800\n",
    "            'gamma': [0]} #Se probo con 0,1,5,10\n",
    "\n",
    "#Estos son sin correccion de metros\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7214816192533363\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7218556040564428\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7219040830119198\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7242695855881088\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7245128843441556\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7246402143520269\n",
    "\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train,\n",
    "         y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
