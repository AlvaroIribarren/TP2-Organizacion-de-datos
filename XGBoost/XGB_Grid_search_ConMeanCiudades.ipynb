{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n",
      "576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                              int64\n",
       "titulo                         object\n",
       "descripcion                    object\n",
       "tipodepropiedad                object\n",
       "direccion                      object\n",
       "ciudad                        float32\n",
       "provincia                      object\n",
       "antiguedad                    float64\n",
       "habitaciones                  float64\n",
       "garages                       float64\n",
       "banos                         float64\n",
       "metroscubiertos               float64\n",
       "metrostotales                 float64\n",
       "idzona                        float64\n",
       "lat                           float64\n",
       "lng                           float64\n",
       "fecha                          object\n",
       "gimnasio                      float64\n",
       "usosmultiples                 float64\n",
       "piscina                       float64\n",
       "escuelascercanas              float64\n",
       "centroscomercialescercanos    float64\n",
       "precio                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ciudades = df_train.groupby('ciudad').agg({'metrostotales':'mean'})\n",
    "df_ciudades2 = df_test.groupby('ciudad').agg({'metrostotales':'mean'})\n",
    "\n",
    "df_ciudades2.reset_index(inplace = True)\n",
    "ciudades_list2 = df_ciudades2.values.tolist()\n",
    "\n",
    "df_ciudades.reset_index(inplace = True)\n",
    "ciudades_list = df_ciudades.values.tolist()\n",
    "\n",
    "only_ciudades_train = []\n",
    "only_ciudades_test = []\n",
    "for ciudades in ciudades_list:\n",
    "    only_ciudades_train.append(ciudades[0])\n",
    "\n",
    "for ciudades in ciudades_list2:\n",
    "    only_ciudades_test.append(ciudades[0])\n",
    "    \n",
    "print(len(only_ciudades_train))\n",
    "print(len(only_ciudades_test))\n",
    "\n",
    "dif = []\n",
    "\n",
    "for ciudad in only_ciudades_test:\n",
    "    if ciudad not in only_ciudades_train:\n",
    "        dif.append(ciudad)\n",
    "        \n",
    "for ciudad in dif:\n",
    "    ciudades_list.append([ciudad,'nan'])\n",
    "\n",
    "#print(ciudades_list)\n",
    "        \n",
    "for i in range (0,len(ciudades_list)):\n",
    "    df_train.loc[df_train.ciudad == ciudades_list[i][0], 'ciudad'] = float(ciudades_list[i][1])\n",
    "    df_test.loc[df_test.ciudad == ciudades_list[i][0], 'ciudad'] = float(ciudades_list[i][1])\n",
    "    \n",
    "df_train.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "df_test.apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "df_train.astype({'ciudad': 'float64'})\n",
    "df_test.astype({'ciudad': 'float64'})\n",
    "\n",
    "df_train['ciudad'] = pd.to_numeric(df_train['ciudad'], downcast='float')\n",
    "df_test['ciudad'] = pd.to_numeric(df_test['ciudad'], downcast='float')\n",
    "\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   2 | elapsed:  4.6min finished\n",
      "c:\\users\\manuel\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "c:\\users\\manuel\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7706985066967957\n",
      "{'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "#----------------PREPROCESAMIENTO----------------\n",
    "\n",
    "df_train = df_train.drop(['fecha','titulo','descripcion','direccion','idzona','lat','lng'], axis=1)\n",
    "df_test = df_test.drop(['fecha','titulo','descripcion','direccion','idzona','lat','lng'], axis=1)\n",
    "df_train = df_train.fillna(value = {'provincia': 0, 'tipodepropiedad': 0})\n",
    "\n",
    "#XGBoost maneja los NaNs, ver despues si lo dejamos como esta\n",
    "\n",
    "df_train = pd.get_dummies(df_train, drop_first=True)#, sparse = True)\n",
    "df_test = pd.get_dummies(df_test, drop_first=True)#, sparse = True)\n",
    "\n",
    "#print(df_train_xgboost.shape)\n",
    "#precio = df_train_xgboost['precio']\n",
    "#df_train_xgboost.drop(labels=['precio'], axis=1,inplace = True)\n",
    "#df_train_xgboost.insert(len(df_train_xgboost.columns), 'Precio', precio)\n",
    "\n",
    "#X_train, y_train = df_train_xgboost.iloc[:,:-1],df_train_xgboost.iloc[:,-1]\n",
    "\n",
    "X = df_train.drop(\"precio\", axis=1)\n",
    "y = df_train['precio']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1)\n",
    "\n",
    "#df_test_xgboost['tipodepropiedad_Garage'] = 0\n",
    "#df_test_xgboost['tipodepropiedad_Hospedaje'] = 0\n",
    "#df_test_xgboost = df_test_xgboost[list(X_train.columns.values)]\n",
    "\n",
    "xgb1 = XGBRegressor()\n",
    "\n",
    "#Ir cambiando parametros para ver como functiona\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [0.04], #probamos con 0.03,0.04,0.05,0.06,0.07\n",
    "              'max_depth': [9], #probamos con 5,6,7,8,9,10,11\n",
    "              'min_child_weight': [1], #Probamos con 1,2,3,4,5,6\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7], #probamos 0.3,0.4,0.5,0.6,0.7,0.8\n",
    "              'n_estimators': [700],  #Se probo con 400,500,600,700,800\n",
    "            'gamma': [0]} #Se probo con 0,1,5,10\n",
    "\n",
    "#Estos son sin correccion de metros\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7214816192533363\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7218556040564428\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7219040830119198\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7242695855881088\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7245128843441556\n",
    "#Con {'colsample_bytree': 0.7, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 700, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7} da 0.7246402143520269\n",
    "\n",
    "#Con fechas nos da 0.7438760200186147\n",
    "\n",
    "#Con las ciudades nos dio 0.7706985066967957\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X,\n",
    "         y)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
